{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['name', 'host_identity_verified', 'host_name', 'neighbourhood_group',\n",
      "       'neighbourhood', 'cancellation_policy', 'room_type', 'last_review',\n",
      "       'house_rules'],\n",
      "      dtype='object')\n",
      "Data types after encoding:\n",
      " id                                  int64\n",
      "name                                int64\n",
      "host_id                             int64\n",
      "host_identity_verified              int64\n",
      "host_name                           int64\n",
      "neighbourhood_group                 int64\n",
      "neighbourhood                       int64\n",
      "lat                               float64\n",
      "long                              float64\n",
      "instant_bookable                     bool\n",
      "cancellation_policy                 int64\n",
      "room_type                           int64\n",
      "construction_year                 float64\n",
      "price                             float64\n",
      "service_fee                       float64\n",
      "minimum_nights                    float64\n",
      "number_of_reviews                 float64\n",
      "last_review                         int64\n",
      "reviews_per_month                 float64\n",
      "review_rate_number                float64\n",
      "calculated_host_listings_count    float64\n",
      "availability_365                  float64\n",
      "house_rules                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "# 加载数据\n",
    "file_path_clean = '/home/sdong/data/airbnb/Airbnb_Open_Data_Alignement.csv'\n",
    "data_df = pd.read_csv(file_path_clean)\n",
    "# 使用 fillna() 方法替换所有的 NaN 值为 0\n",
    "data_df.fillna(0, inplace=True)\n",
    "# 检查非数值列\n",
    "non_numeric_cols = data_df.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)\n",
    "\n",
    "# 将非数值列转换为数值类型（使用标签编码）\n",
    "label_encoders = {}\n",
    "for col in non_numeric_cols:\n",
    "    le = LabelEncoder()\n",
    "    data_df[col] = le.fit_transform(data_df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 确保所有特征列都是数值类型\n",
    "print(\"Data types after encoding:\\n\", data_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数值特征\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_df)\n",
    "\n",
    "# 将标准化后的数据转换为torch张量\n",
    "x = torch.tensor(data_scaled, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 2.57453371e-01, 8.09927687e-01, ...,\n",
       "        1.80722892e-02, 8.02820721e-02, 2.25202429e-01],\n",
       "       [1.50444869e-05, 7.81987892e-01, 5.29316929e-01, ...,\n",
       "        6.02409639e-03, 6.45511256e-02, 6.16902834e-01],\n",
       "       [2.03845701e-05, 9.03281604e-01, 7.97911752e-01, ...,\n",
       "        3.01204819e-03, 9.81828044e-02, 2.95546559e-01],\n",
       "       ...,\n",
       "       [9.03429953e-02, 2.80331587e-01, 6.98773960e-01, ...,\n",
       "        3.01204819e-03, 9.54705723e-02, 1.04251012e-01],\n",
       "       [9.03527884e-02, 1.63623309e-01, 1.11892169e-01, ...,\n",
       "        3.01204819e-03, 1.07404394e-01, 1.04251012e-01],\n",
       "       [9.03625993e-02, 5.86315497e-02, 6.89855618e-01, ...,\n",
       "        3.01204819e-03, 2.14266341e-02, 1.04251012e-01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 14], num_nodes=23, x=[69305, 23])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 定义特征列和关系\n",
    "columns = [\n",
    "    'id', 'name', 'host_id', 'host_identity_verified', 'host_name',\n",
    "    'neighbourhood_group', 'neighbourhood', 'lat', 'long',\n",
    "    'instant_bookable', 'cancellation_policy', 'room_type',\n",
    "    'construction_year', 'price', 'service_fee', 'minimum_nights',\n",
    "    'number_of_reviews', 'last_review', 'reviews_per_month',\n",
    "    'review_rate_number', 'calculated_host_listings_count', 'availability_365',\n",
    "    'house_rules'\n",
    "]\n",
    "\n",
    "relations = [\n",
    "    ('id', 'host_id'),\n",
    "    ('host_id', 'host_identity_verified'),\n",
    "    ('host_id', 'host_name'),\n",
    "    ('neighbourhood_group', 'neighbourhood'),\n",
    "    ('lat', 'long'),\n",
    "    ('instant_bookable', 'cancellation_policy'),\n",
    "    ('room_type', 'price'),\n",
    "    ('price', 'service_fee'),\n",
    "    ('minimum_nights', 'number_of_reviews'),\n",
    "    ('number_of_reviews', 'reviews_per_month'),\n",
    "    ('reviews_per_month', 'review_rate_number'),\n",
    "    ('review_rate_number', 'calculated_host_listings_count'),\n",
    "    ('calculated_host_listings_count', 'availability_365'),\n",
    "    ('availability_365', 'house_rules')\n",
    "]\n",
    "\n",
    "# 创建空的无向图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加节点（每个特征作为一个节点）\n",
    "for col in columns:\n",
    "    G.add_node(col)\n",
    "\n",
    "# 添加边（根据特征之间的关系）\n",
    "for relation in relations:\n",
    "    G.add_edge(relation[0], relation[1])\n",
    "\n",
    "# 将NetworkX图转换为PyTorch Geometric图\n",
    "data = from_networkx(G)\n",
    "\n",
    "# 添加节点特征\n",
    "data.x = x\n",
    "\n",
    "# 映射特征列到索引\n",
    "feature_to_index = {col: i for i, col in enumerate(columns)}\n",
    "\n",
    "# 映射关系到索引\n",
    "edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "# 添加边\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "data.edge_index = edge_index\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(23, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (fc): Linear(in_features=128, out_features=23, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, output_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = nn.Linear(hidden_channels, output_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "num_features = data.num_features\n",
    "hidden_channels = 128\n",
    "output_channels = num_features  # 确保输出维度与输入维度一致\n",
    "model = GCN(num_features, hidden_channels, output_channels)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0786\n",
      "Epoch 20, Loss: 0.0417\n",
      "Epoch 30, Loss: 0.0207\n",
      "Epoch 40, Loss: 0.0097\n",
      "Epoch 50, Loss: 0.0062\n",
      "Epoch 60, Loss: 0.0037\n",
      "Epoch 70, Loss: 0.0023\n",
      "Epoch 80, Loss: 0.0016\n",
      "Epoch 90, Loss: 0.0019\n",
      "Epoch 100, Loss: 0.0011\n",
      "Epoch 110, Loss: 0.0021\n",
      "Epoch 120, Loss: 0.0013\n",
      "Epoch 130, Loss: 0.0008\n",
      "Epoch 140, Loss: 0.0006\n",
      "Epoch 150, Loss: 0.0005\n",
      "Epoch 160, Loss: 0.0008\n",
      "Epoch 170, Loss: 0.0006\n",
      "Epoch 180, Loss: 0.0003\n",
      "Epoch 190, Loss: 0.0003\n",
      "Epoch 200, Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# 创建数据加载器\n",
    "loader = DataLoader([data], batch_size=1, shuffle=True)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 训练模型\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.1696e-04,  2.2841e-01,  9.0309e-01,  ...,  3.3610e-02,\n",
      "          7.9161e-02,  2.6281e-01],\n",
      "        [ 1.8874e-03,  8.2570e-01,  6.1290e-01,  ...,  2.4196e-02,\n",
      "          5.4390e-02,  6.9737e-01],\n",
      "        [-4.9829e-03,  8.9552e-01,  8.7455e-01,  ...,  2.0388e-02,\n",
      "          1.4050e-01,  3.9682e-01],\n",
      "        ...,\n",
      "        [ 8.8830e-02,  2.7736e-01,  7.8720e-01,  ...,  9.4586e-03,\n",
      "          1.0766e-01,  1.4798e-01],\n",
      "        [ 8.6810e-02,  1.1454e-01,  1.6845e-01,  ...,  1.2470e-02,\n",
      "          1.2308e-01,  1.7409e-01],\n",
      "        [ 1.3753e-01,  1.6423e-01,  7.2028e-01,  ...,  2.2947e-02,\n",
      "          4.9947e-02,  9.8170e-02]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "def aggregate_instance_embeddings(data_scaled, G, model):\n",
    "    model.eval()\n",
    "    instance_embeddings_list = []\n",
    "\n",
    "    for i in range(len(data_scaled)):\n",
    "        # 创建子图\n",
    "        subgraph = G.copy()\n",
    "\n",
    "        # 创建节点特征张量\n",
    "        subgraph_data = data_scaled[i]\n",
    "\n",
    "        # 确保 x 的形状是 [num_nodes, num_features]，即 [1, 23]\n",
    "        node_features = torch.tensor(subgraph_data, dtype=torch.float).view(1, -1).repeat(len(columns), 1)\n",
    "\n",
    "        # 将 NetworkX 子图转换为 PyTorch Geometric 图\n",
    "        subgraph_data = from_networkx(subgraph)\n",
    "\n",
    "        # 更新子图的节点特征\n",
    "        subgraph_data.x = node_features\n",
    "\n",
    "        # 映射特征列到索引\n",
    "        feature_to_index = {col: idx for idx, col in enumerate(columns)}\n",
    "\n",
    "        # 映射关系到索引\n",
    "        edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "        # 添加边\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        subgraph_data.edge_index = edge_index\n",
    "\n",
    "        # 获取特征嵌入\n",
    "        with torch.no_grad():\n",
    "            node_embeddings = model(subgraph_data)\n",
    "\n",
    "        # 聚合节点嵌入到实例嵌入\n",
    "        instance_embedding = node_embeddings.mean(dim=0, keepdim=True)\n",
    "        instance_embeddings_list.append(instance_embedding)\n",
    "\n",
    "    instance_embeddings = torch.cat(instance_embeddings_list, dim=0)\n",
    "    return instance_embeddings\n",
    "\n",
    "# 获取每个实例的特征嵌入\n",
    "instance_embeddings = aggregate_instance_embeddings(data_scaled, G, model)\n",
    "print(instance_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102599, 23])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.228405</td>\n",
       "      <td>0.903086</td>\n",
       "      <td>0.545298</td>\n",
       "      <td>0.629540</td>\n",
       "      <td>0.359283</td>\n",
       "      <td>0.637048</td>\n",
       "      <td>1.215665</td>\n",
       "      <td>0.092474</td>\n",
       "      <td>-0.047036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856802</td>\n",
       "      <td>0.887323</td>\n",
       "      <td>0.205695</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.113142</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.922144</td>\n",
       "      <td>0.033610</td>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.262806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.825697</td>\n",
       "      <td>0.612899</td>\n",
       "      <td>1.114049</td>\n",
       "      <td>0.463659</td>\n",
       "      <td>0.501175</td>\n",
       "      <td>0.694174</td>\n",
       "      <td>1.191927</td>\n",
       "      <td>0.096524</td>\n",
       "      <td>-0.014130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097614</td>\n",
       "      <td>0.111331</td>\n",
       "      <td>0.221673</td>\n",
       "      <td>0.092999</td>\n",
       "      <td>0.630479</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.918670</td>\n",
       "      <td>0.024196</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.697367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0.895520</td>\n",
       "      <td>0.874546</td>\n",
       "      <td>0.073093</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>0.528250</td>\n",
       "      <td>0.542141</td>\n",
       "      <td>1.165342</td>\n",
       "      <td>0.157214</td>\n",
       "      <td>1.058975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535398</td>\n",
       "      <td>0.563650</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>-0.016262</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>1.134149</td>\n",
       "      <td>0.020388</td>\n",
       "      <td>0.140503</td>\n",
       "      <td>0.396822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.030835</td>\n",
       "      <td>0.949625</td>\n",
       "      <td>0.607958</td>\n",
       "      <td>0.356957</td>\n",
       "      <td>0.373027</td>\n",
       "      <td>0.260671</td>\n",
       "      <td>1.162637</td>\n",
       "      <td>0.155808</td>\n",
       "      <td>1.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337681</td>\n",
       "      <td>0.355100</td>\n",
       "      <td>0.295010</td>\n",
       "      <td>0.185314</td>\n",
       "      <td>0.893623</td>\n",
       "      <td>0.062765</td>\n",
       "      <td>0.868270</td>\n",
       "      <td>-0.012259</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>0.181288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016050</td>\n",
       "      <td>0.394878</td>\n",
       "      <td>1.044880</td>\n",
       "      <td>1.108192</td>\n",
       "      <td>0.613007</td>\n",
       "      <td>0.493131</td>\n",
       "      <td>0.364837</td>\n",
       "      <td>1.190292</td>\n",
       "      <td>0.096336</td>\n",
       "      <td>-0.014566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158645</td>\n",
       "      <td>0.184044</td>\n",
       "      <td>0.213740</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.198182</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.717442</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.790252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.517158</td>\n",
       "      <td>0.540633</td>\n",
       "      <td>1.106703</td>\n",
       "      <td>0.687191</td>\n",
       "      <td>0.503082</td>\n",
       "      <td>0.749124</td>\n",
       "      <td>1.204429</td>\n",
       "      <td>0.083236</td>\n",
       "      <td>1.091774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493595</td>\n",
       "      <td>0.507369</td>\n",
       "      <td>0.212985</td>\n",
       "      <td>0.118647</td>\n",
       "      <td>0.732939</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.701882</td>\n",
       "      <td>0.021983</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.639099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.152125</td>\n",
       "      <td>0.737456</td>\n",
       "      <td>0.147463</td>\n",
       "      <td>0.141006</td>\n",
       "      <td>0.340436</td>\n",
       "      <td>0.195361</td>\n",
       "      <td>1.042977</td>\n",
       "      <td>0.189862</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130989</td>\n",
       "      <td>0.138987</td>\n",
       "      <td>0.251169</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.238323</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>1.042127</td>\n",
       "      <td>-0.036534</td>\n",
       "      <td>0.124290</td>\n",
       "      <td>0.793922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.995539</td>\n",
       "      <td>0.566390</td>\n",
       "      <td>0.285671</td>\n",
       "      <td>0.350565</td>\n",
       "      <td>0.127371</td>\n",
       "      <td>1.205168</td>\n",
       "      <td>0.117458</td>\n",
       "      <td>-0.009812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923621</td>\n",
       "      <td>0.955438</td>\n",
       "      <td>0.253155</td>\n",
       "      <td>0.039116</td>\n",
       "      <td>0.199725</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>1.104583</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>0.077932</td>\n",
       "      <td>0.322912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.933288</td>\n",
       "      <td>1.128596</td>\n",
       "      <td>0.332370</td>\n",
       "      <td>0.522024</td>\n",
       "      <td>0.538663</td>\n",
       "      <td>1.212869</td>\n",
       "      <td>0.079220</td>\n",
       "      <td>1.094610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898793</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.260169</td>\n",
       "      <td>0.805860</td>\n",
       "      <td>0.080660</td>\n",
       "      <td>0.701076</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>0.050210</td>\n",
       "      <td>0.107146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.269740</td>\n",
       "      <td>0.855700</td>\n",
       "      <td>0.580562</td>\n",
       "      <td>0.183023</td>\n",
       "      <td>0.521468</td>\n",
       "      <td>1.073456</td>\n",
       "      <td>1.184218</td>\n",
       "      <td>0.115331</td>\n",
       "      <td>-0.027040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240505</td>\n",
       "      <td>0.250790</td>\n",
       "      <td>0.239179</td>\n",
       "      <td>0.135944</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>1.114009</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.117485</td>\n",
       "      <td>0.436383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.023854</td>\n",
       "      <td>0.361938</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>1.084776</td>\n",
       "      <td>0.684304</td>\n",
       "      <td>0.495498</td>\n",
       "      <td>0.251619</td>\n",
       "      <td>1.144854</td>\n",
       "      <td>0.102964</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260020</td>\n",
       "      <td>0.285544</td>\n",
       "      <td>0.230238</td>\n",
       "      <td>0.160113</td>\n",
       "      <td>0.814002</td>\n",
       "      <td>0.043435</td>\n",
       "      <td>0.684419</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.006455</td>\n",
       "      <td>0.183831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>1.121193</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.501981</td>\n",
       "      <td>1.069233</td>\n",
       "      <td>1.185644</td>\n",
       "      <td>0.126205</td>\n",
       "      <td>1.080140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515530</td>\n",
       "      <td>0.536835</td>\n",
       "      <td>0.240366</td>\n",
       "      <td>0.097110</td>\n",
       "      <td>0.744366</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.904060</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.043581</td>\n",
       "      <td>0.420763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.005103</td>\n",
       "      <td>0.192118</td>\n",
       "      <td>1.003921</td>\n",
       "      <td>1.111682</td>\n",
       "      <td>0.021757</td>\n",
       "      <td>0.526039</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>1.192223</td>\n",
       "      <td>0.097063</td>\n",
       "      <td>-0.013307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631729</td>\n",
       "      <td>0.652345</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.162095</td>\n",
       "      <td>0.769630</td>\n",
       "      <td>0.047271</td>\n",
       "      <td>0.916917</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.081034</td>\n",
       "      <td>0.102308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.027744</td>\n",
       "      <td>0.556559</td>\n",
       "      <td>0.345341</td>\n",
       "      <td>1.115845</td>\n",
       "      <td>0.246845</td>\n",
       "      <td>0.982571</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>1.201473</td>\n",
       "      <td>0.120618</td>\n",
       "      <td>1.086347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493370</td>\n",
       "      <td>0.518912</td>\n",
       "      <td>0.234011</td>\n",
       "      <td>0.151453</td>\n",
       "      <td>0.747279</td>\n",
       "      <td>0.047022</td>\n",
       "      <td>0.927733</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.014917</td>\n",
       "      <td>0.136570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021317</td>\n",
       "      <td>1.033263</td>\n",
       "      <td>1.011796</td>\n",
       "      <td>1.111141</td>\n",
       "      <td>0.591755</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>1.059816</td>\n",
       "      <td>1.175909</td>\n",
       "      <td>0.092920</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119446</td>\n",
       "      <td>0.135041</td>\n",
       "      <td>0.209095</td>\n",
       "      <td>0.154245</td>\n",
       "      <td>0.870773</td>\n",
       "      <td>0.044022</td>\n",
       "      <td>0.722724</td>\n",
       "      <td>0.030171</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.143064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.012047</td>\n",
       "      <td>0.966314</td>\n",
       "      <td>0.508755</td>\n",
       "      <td>1.143787</td>\n",
       "      <td>0.208119</td>\n",
       "      <td>0.511007</td>\n",
       "      <td>1.112782</td>\n",
       "      <td>1.165686</td>\n",
       "      <td>0.194524</td>\n",
       "      <td>1.094030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258286</td>\n",
       "      <td>0.277088</td>\n",
       "      <td>0.233842</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>0.181344</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>0.772153</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.039496</td>\n",
       "      <td>0.283357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.662445</td>\n",
       "      <td>0.603329</td>\n",
       "      <td>0.375202</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>1.118129</td>\n",
       "      <td>1.136280</td>\n",
       "      <td>0.229516</td>\n",
       "      <td>1.113092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360865</td>\n",
       "      <td>0.352395</td>\n",
       "      <td>0.259032</td>\n",
       "      <td>0.106058</td>\n",
       "      <td>0.791769</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.765018</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.300170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.013974</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.876988</td>\n",
       "      <td>1.163558</td>\n",
       "      <td>0.855300</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0.461469</td>\n",
       "      <td>1.145289</td>\n",
       "      <td>0.201218</td>\n",
       "      <td>1.099077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>0.301184</td>\n",
       "      <td>0.228301</td>\n",
       "      <td>0.144916</td>\n",
       "      <td>0.794837</td>\n",
       "      <td>0.037913</td>\n",
       "      <td>1.213950</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.036979</td>\n",
       "      <td>0.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.048036</td>\n",
       "      <td>0.242886</td>\n",
       "      <td>0.811676</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>0.026481</td>\n",
       "      <td>1.042567</td>\n",
       "      <td>0.301642</td>\n",
       "      <td>1.130567</td>\n",
       "      <td>0.186788</td>\n",
       "      <td>1.049393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235711</td>\n",
       "      <td>0.233328</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.173483</td>\n",
       "      <td>0.816445</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.808804</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.131647</td>\n",
       "      <td>0.203116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.340382</td>\n",
       "      <td>0.741027</td>\n",
       "      <td>0.058263</td>\n",
       "      <td>0.630730</td>\n",
       "      <td>0.358978</td>\n",
       "      <td>0.304004</td>\n",
       "      <td>1.104761</td>\n",
       "      <td>0.301655</td>\n",
       "      <td>1.118337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520538</td>\n",
       "      <td>0.500691</td>\n",
       "      <td>0.267695</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>0.757312</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>1.238708</td>\n",
       "      <td>0.019792</td>\n",
       "      <td>0.154009</td>\n",
       "      <td>0.520451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000817  0.228405  0.903086  0.545298  0.629540  0.359283  0.637048   \n",
       "1   0.001887  0.825697  0.612899  1.114049  0.463659  0.501175  0.694174   \n",
       "2  -0.004983  0.895520  0.874546  0.073093  0.344979  0.528250  0.542141   \n",
       "3  -0.000201 -0.030835  0.949625  0.607958  0.356957  0.373027  0.260671   \n",
       "4  -0.016050  0.394878  1.044880  1.108192  0.613007  0.493131  0.364837   \n",
       "5   0.000750  0.517158  0.540633  1.106703  0.687191  0.503082  0.749124   \n",
       "6   0.023750  0.152125  0.737456  0.147463  0.141006  0.340436  0.195361   \n",
       "7   0.008559  0.174777  0.995539  0.566390  0.285671  0.350565  0.127371   \n",
       "8  -0.069995  0.507579  0.933288  1.128596  0.332370  0.522024  0.538663   \n",
       "9   0.017373  0.269740  0.855700  0.580562  0.183023  0.521468  1.073456   \n",
       "10 -0.023854  0.361938  0.044025  1.084776  0.684304  0.495498  0.251619   \n",
       "11  0.007053  0.079005  0.248265  1.121193  0.056500  0.501981  1.069233   \n",
       "12 -0.005103  0.192118  1.003921  1.111682  0.021757  0.526039  0.539493   \n",
       "13 -0.027744  0.556559  0.345341  1.115845  0.246845  0.982571  0.959601   \n",
       "14  0.021317  1.033263  1.011796  1.111141  0.591755  0.525795  1.059816   \n",
       "15 -0.012047  0.966314  0.508755  1.143787  0.208119  0.511007  1.112782   \n",
       "16  0.005596  0.585526  0.662445  0.603329  0.375202  0.362066  1.118129   \n",
       "17 -0.013974  0.631000  0.876988  1.163558  0.855300  0.364464  0.461469   \n",
       "18 -0.048036  0.242886  0.811676  1.049180  0.026481  1.042567  0.301642   \n",
       "19  0.035645  0.340382  0.741027  0.058263  0.630730  0.358978  0.304004   \n",
       "\n",
       "          7         8         9   ...        13        14        15        16  \\\n",
       "0   1.215665  0.092474 -0.047036  ...  0.856802  0.887323  0.205695  0.006652   \n",
       "1   1.191927  0.096524 -0.014130  ...  0.097614  0.111331  0.221673  0.092999   \n",
       "2   1.165342  0.157214  1.058975  ...  0.535398  0.563650  0.271500 -0.016262   \n",
       "3   1.162637  0.155808  1.061224  ...  0.337681  0.355100  0.295010  0.185314   \n",
       "4   1.190292  0.096336 -0.014566  ...  0.158645  0.184044  0.213740  0.025236   \n",
       "5   1.204429  0.083236  1.091774  ...  0.493595  0.507369  0.212985  0.118647   \n",
       "6   1.042977  0.189862  0.039007  ...  0.130989  0.138987  0.251169  0.000879   \n",
       "7   1.205168  0.117458 -0.009812  ...  0.923621  0.955438  0.253155  0.039116   \n",
       "8   1.212869  0.079220  1.094610  ...  0.898793  0.936768  0.242000  0.260169   \n",
       "9   1.184218  0.115331 -0.027040  ...  0.240505  0.250790  0.239179  0.135944   \n",
       "10  1.144854  0.102964  0.025035  ...  0.260020  0.285544  0.230238  0.160113   \n",
       "11  1.185644  0.126205  1.080140  ...  0.515530  0.536835  0.240366  0.097110   \n",
       "12  1.192223  0.097063 -0.013307  ...  0.631729  0.652345  0.227790  0.162095   \n",
       "13  1.201473  0.120618  1.086347  ...  0.493370  0.518912  0.234011  0.151453   \n",
       "14  1.175909  0.092920 -0.010429  ...  0.119446  0.135041  0.209095  0.154245   \n",
       "15  1.165686  0.194524  1.094030  ...  0.258286  0.277088  0.233842 -0.002230   \n",
       "16  1.136280  0.229516  1.113092  ...  0.360865  0.352395  0.259032  0.106058   \n",
       "17  1.145289  0.201218  1.099077  ...  0.296782  0.301184  0.228301  0.144916   \n",
       "18  1.130567  0.186788  1.049393  ...  0.235711  0.233328  0.288043  0.173483   \n",
       "19  1.104761  0.301655  1.118337  ...  0.520538  0.500691  0.267695  0.060704   \n",
       "\n",
       "          17        18        19        20        21        22  \n",
       "0   0.113142  0.000424  0.922144  0.033610  0.079161  0.262806  \n",
       "1   0.630479  0.022897  0.918670  0.024196  0.054390  0.697367  \n",
       "2   0.007722  0.009327  1.134149  0.020388  0.140503  0.396822  \n",
       "3   0.893623  0.062765  0.868270 -0.012259  0.090245  0.181288  \n",
       "4   0.198182  0.003554  0.717442  0.024944  0.069941  0.790252  \n",
       "5   0.732939  0.028568  0.701882  0.021983  0.094527  0.639099  \n",
       "6   0.238323 -0.002531  1.042127 -0.036534  0.124290  0.793922  \n",
       "7   0.199725  0.007609  1.104583  0.016661  0.077932  0.322912  \n",
       "8   0.805860  0.080660  0.701076 -0.001060  0.050210  0.107146  \n",
       "9   0.835459  0.036736  1.114009  0.008020  0.117485  0.436383  \n",
       "10  0.814002  0.043435  0.684419  0.023625  0.006455  0.183831  \n",
       "11  0.744366  0.029123  0.904060  0.017187  0.043581  0.420763  \n",
       "12  0.769630  0.047271  0.916917  0.014972  0.081034  0.102308  \n",
       "13  0.747279  0.047022  0.927733  0.024772  0.014917  0.136570  \n",
       "14  0.870773  0.044022  0.722724  0.030171  0.010807  0.143064  \n",
       "15  0.181344 -0.002213  0.772153  0.032391  0.039496  0.283357  \n",
       "16  0.791769  0.026461  0.765018  0.010719  0.089489  0.300170  \n",
       "17  0.794837  0.037913  1.213950  0.021237  0.036979  0.142967  \n",
       "18  0.816445  0.043340  0.808804 -0.002834  0.131647  0.203116  \n",
       "19  0.757312  0.015205  1.238708  0.019792  0.154009  0.520451  \n",
       "\n",
       "[20 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 PyTorch 张量转换为 Pandas DataFrame\n",
    "instance_embeddings_df = pd.DataFrame(instance_embeddings.numpy())\n",
    "\n",
    "instance_embeddings_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087731</td>\n",
       "      <td>0.277903</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.485925</td>\n",
       "      <td>0.560251</td>\n",
       "      <td>0.331498</td>\n",
       "      <td>0.511577</td>\n",
       "      <td>0.895001</td>\n",
       "      <td>0.186125</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786301</td>\n",
       "      <td>0.784521</td>\n",
       "      <td>0.175918</td>\n",
       "      <td>0.261275</td>\n",
       "      <td>0.120776</td>\n",
       "      <td>0.149842</td>\n",
       "      <td>0.707220</td>\n",
       "      <td>0.073963</td>\n",
       "      <td>0.118308</td>\n",
       "      <td>0.242640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088619</td>\n",
       "      <td>0.765511</td>\n",
       "      <td>0.526727</td>\n",
       "      <td>0.937501</td>\n",
       "      <td>0.418205</td>\n",
       "      <td>0.470320</td>\n",
       "      <td>0.560032</td>\n",
       "      <td>0.876064</td>\n",
       "      <td>0.189820</td>\n",
       "      <td>0.048189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119303</td>\n",
       "      <td>0.115024</td>\n",
       "      <td>0.190432</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>0.570463</td>\n",
       "      <td>0.233505</td>\n",
       "      <td>0.704495</td>\n",
       "      <td>0.065883</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.609514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082920</td>\n",
       "      <td>0.822512</td>\n",
       "      <td>0.736786</td>\n",
       "      <td>0.111006</td>\n",
       "      <td>0.316577</td>\n",
       "      <td>0.496809</td>\n",
       "      <td>0.431075</td>\n",
       "      <td>0.854856</td>\n",
       "      <td>0.245189</td>\n",
       "      <td>0.927073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503926</td>\n",
       "      <td>0.505268</td>\n",
       "      <td>0.235693</td>\n",
       "      <td>0.222982</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>0.182987</td>\n",
       "      <td>0.873533</td>\n",
       "      <td>0.062614</td>\n",
       "      <td>0.172560</td>\n",
       "      <td>0.355782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.086887</td>\n",
       "      <td>0.066268</td>\n",
       "      <td>0.797063</td>\n",
       "      <td>0.535676</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>0.344945</td>\n",
       "      <td>0.192328</td>\n",
       "      <td>0.852697</td>\n",
       "      <td>0.243907</td>\n",
       "      <td>0.928914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330218</td>\n",
       "      <td>0.325339</td>\n",
       "      <td>0.257048</td>\n",
       "      <td>0.559852</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.381927</td>\n",
       "      <td>0.664958</td>\n",
       "      <td>0.034593</td>\n",
       "      <td>0.128111</td>\n",
       "      <td>0.173818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073741</td>\n",
       "      <td>0.413806</td>\n",
       "      <td>0.873537</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>0.546094</td>\n",
       "      <td>0.462450</td>\n",
       "      <td>0.280683</td>\n",
       "      <td>0.874760</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>0.047833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172923</td>\n",
       "      <td>0.177758</td>\n",
       "      <td>0.183226</td>\n",
       "      <td>0.292333</td>\n",
       "      <td>0.194696</td>\n",
       "      <td>0.161495</td>\n",
       "      <td>0.546637</td>\n",
       "      <td>0.066525</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.687932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.087676</td>\n",
       "      <td>0.513630</td>\n",
       "      <td>0.468710</td>\n",
       "      <td>0.931668</td>\n",
       "      <td>0.609619</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.606641</td>\n",
       "      <td>0.886038</td>\n",
       "      <td>0.177697</td>\n",
       "      <td>0.953935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467199</td>\n",
       "      <td>0.456711</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.448440</td>\n",
       "      <td>0.659525</td>\n",
       "      <td>0.254617</td>\n",
       "      <td>0.534430</td>\n",
       "      <td>0.063983</td>\n",
       "      <td>0.131897</td>\n",
       "      <td>0.560322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.106753</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>0.626726</td>\n",
       "      <td>0.170054</td>\n",
       "      <td>0.141912</td>\n",
       "      <td>0.313059</td>\n",
       "      <td>0.136931</td>\n",
       "      <td>0.757237</td>\n",
       "      <td>0.274975</td>\n",
       "      <td>0.091709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148626</td>\n",
       "      <td>0.138885</td>\n",
       "      <td>0.217225</td>\n",
       "      <td>0.251627</td>\n",
       "      <td>0.229588</td>\n",
       "      <td>0.138845</td>\n",
       "      <td>0.801344</td>\n",
       "      <td>0.013757</td>\n",
       "      <td>0.158220</td>\n",
       "      <td>0.691030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.094153</td>\n",
       "      <td>0.234123</td>\n",
       "      <td>0.833924</td>\n",
       "      <td>0.502672</td>\n",
       "      <td>0.265791</td>\n",
       "      <td>0.322968</td>\n",
       "      <td>0.079261</td>\n",
       "      <td>0.886627</td>\n",
       "      <td>0.208919</td>\n",
       "      <td>0.051726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845006</td>\n",
       "      <td>0.843287</td>\n",
       "      <td>0.219029</td>\n",
       "      <td>0.315528</td>\n",
       "      <td>0.196037</td>\n",
       "      <td>0.176594</td>\n",
       "      <td>0.850339</td>\n",
       "      <td>0.059415</td>\n",
       "      <td>0.117221</td>\n",
       "      <td>0.293384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.028994</td>\n",
       "      <td>0.505810</td>\n",
       "      <td>0.783947</td>\n",
       "      <td>0.949050</td>\n",
       "      <td>0.305780</td>\n",
       "      <td>0.490718</td>\n",
       "      <td>0.428125</td>\n",
       "      <td>0.892771</td>\n",
       "      <td>0.174033</td>\n",
       "      <td>0.956258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823193</td>\n",
       "      <td>0.827180</td>\n",
       "      <td>0.208896</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>0.722911</td>\n",
       "      <td>0.448547</td>\n",
       "      <td>0.533798</td>\n",
       "      <td>0.044205</td>\n",
       "      <td>0.092703</td>\n",
       "      <td>0.111225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.101464</td>\n",
       "      <td>0.311648</td>\n",
       "      <td>0.721656</td>\n",
       "      <td>0.513924</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>0.490174</td>\n",
       "      <td>0.881745</td>\n",
       "      <td>0.869914</td>\n",
       "      <td>0.206978</td>\n",
       "      <td>0.037616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244843</td>\n",
       "      <td>0.235344</td>\n",
       "      <td>0.206333</td>\n",
       "      <td>0.477346</td>\n",
       "      <td>0.748639</td>\n",
       "      <td>0.285025</td>\n",
       "      <td>0.857734</td>\n",
       "      <td>0.051998</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>0.389181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.087731  0.277903  0.759700  0.485925  0.560251  0.331498  0.511577   \n",
       "1  0.088619  0.765511  0.526727  0.937501  0.418205  0.470320  0.560032   \n",
       "2  0.082920  0.822512  0.736786  0.111006  0.316577  0.496809  0.431075   \n",
       "3  0.086887  0.066268  0.797063  0.535676  0.326835  0.344945  0.192328   \n",
       "4  0.073741  0.413806  0.873537  0.932850  0.546094  0.462450  0.280683   \n",
       "5  0.087676  0.513630  0.468710  0.931668  0.609619  0.472186  0.606641   \n",
       "6  0.106753  0.215631  0.626726  0.170054  0.141912  0.313059  0.136931   \n",
       "7  0.094153  0.234123  0.833924  0.502672  0.265791  0.322968  0.079261   \n",
       "8  0.028994  0.505810  0.783947  0.949050  0.305780  0.490718  0.428125   \n",
       "9  0.101464  0.311648  0.721656  0.513924  0.177892  0.490174  0.881745   \n",
       "\n",
       "         7         8         9   ...        13        14        15        16  \\\n",
       "0  0.895001  0.186125  0.021239  ...  0.786301  0.784521  0.175918  0.261275   \n",
       "1  0.876064  0.189820  0.048189  ...  0.119303  0.115024  0.190432  0.405577   \n",
       "2  0.854856  0.245189  0.927073  ...  0.503926  0.505268  0.235693  0.222982   \n",
       "3  0.852697  0.243907  0.928914  ...  0.330218  0.325339  0.257048  0.559852   \n",
       "4  0.874760  0.189649  0.047833  ...  0.172923  0.177758  0.183226  0.292333   \n",
       "5  0.886038  0.177697  0.953935  ...  0.467199  0.456711  0.182540  0.448440   \n",
       "6  0.757237  0.274975  0.091709  ...  0.148626  0.138885  0.217225  0.251627   \n",
       "7  0.886627  0.208919  0.051726  ...  0.845006  0.843287  0.219029  0.315528   \n",
       "8  0.892771  0.174033  0.956258  ...  0.823193  0.827180  0.208896  0.684947   \n",
       "9  0.869914  0.206978  0.037616  ...  0.244843  0.235344  0.206333  0.477346   \n",
       "\n",
       "         17        18        19        20        21        22  \n",
       "0  0.120776  0.149842  0.707220  0.073963  0.118308  0.242640  \n",
       "1  0.570463  0.233505  0.704495  0.065883  0.096400  0.609514  \n",
       "2  0.029142  0.182987  0.873533  0.062614  0.172560  0.355782  \n",
       "3  0.799197  0.381927  0.664958  0.034593  0.128111  0.173818  \n",
       "4  0.194696  0.161495  0.546637  0.066525  0.110153  0.687932  \n",
       "5  0.659525  0.254617  0.534430  0.063983  0.131897  0.560322  \n",
       "6  0.229588  0.138845  0.801344  0.013757  0.158220  0.691030  \n",
       "7  0.196037  0.176594  0.850339  0.059415  0.117221  0.293384  \n",
       "8  0.722911  0.448547  0.533798  0.044205  0.092703  0.111225  \n",
       "9  0.748639  0.285025  0.857734  0.051998  0.152203  0.389181  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化数值特征\n",
    "scaler = MinMaxScaler()\n",
    "instance_embeddings_df_scaled = scaler.fit_transform(instance_embeddings_df)\n",
    "# 将标准化后的数据转换回 DataFrame\n",
    "instance_embeddings_df_scaled = pd.DataFrame(instance_embeddings_df_scaled, columns=instance_embeddings_df.columns)\n",
    "\n",
    "instance_embeddings_df_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance embeddings saved to /home/sdong/data/airbnb/Airbnb_Open_Data_Alignement_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存为 CSV 文件\n",
    "csv_file_path = '/home/sdong/data/airbnb/Airbnb_Open_Data_Alignement_embeddings.csv'\n",
    "instance_embeddings_df_scaled.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'Instance embeddings saved to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
