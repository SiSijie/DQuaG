{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "# 加载数据\n",
    "file_path_clean = '/home/sdong/data/taxi/yellow_tripdata_sample.csv'\n",
    "#file_path_clean = '/home/sdong/data/taxi/yellow_tripdata_missing.csv'\n",
    "data_df = pd.read_csv(file_path_clean)\n",
    "\n",
    "# # 保留指定的列\n",
    "# columns_to_keep = [\n",
    "#     \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\",\n",
    "#     \"trip_distance\"\n",
    "# ]\n",
    "# columns_to_keep = [\n",
    "#     \"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\",\n",
    "#     \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\", \"RateCodeID\",\n",
    "#     \"store_and_fwd_flag\", \"dropoff_longitude\"\n",
    "# ]\n",
    "#data_df = data_df[columns_to_keep]\n",
    "\n",
    "print(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index(['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'store_and_fwd_flag'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000000 entries, 919213 to 2187994\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   VendorID               1000000 non-null  int64  \n",
      " 1   tpep_pickup_datetime   1000000 non-null  int64  \n",
      " 2   tpep_dropoff_datetime  1000000 non-null  int64  \n",
      " 3   passenger_count        1000000 non-null  int64  \n",
      " 4   trip_distance          1000000 non-null  float64\n",
      " 5   pickup_longitude       1000000 non-null  float64\n",
      " 6   pickup_latitude        1000000 non-null  float64\n",
      " 7   RateCodeID             1000000 non-null  int64  \n",
      " 8   store_and_fwd_flag     1000000 non-null  int64  \n",
      " 9   dropoff_longitude      1000000 non-null  float64\n",
      " 10  dropoff_latitude       1000000 non-null  float64\n",
      " 11  payment_type           1000000 non-null  int64  \n",
      " 12  fare_amount            1000000 non-null  float64\n",
      " 13  extra                  1000000 non-null  float64\n",
      " 14  mta_tax                1000000 non-null  float64\n",
      " 15  tip_amount             1000000 non-null  float64\n",
      " 16  tolls_amount           1000000 non-null  float64\n",
      " 17  total_amount           1000000 non-null  float64\n",
      "dtypes: float64(11), int64(7)\n",
      "memory usage: 145.0 MB\n",
      "Data types after encoding:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# 随机选择20分之一个数据集（即5%）\n",
    "data_df = data_df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# 使用 fillna() 方法替换所有的 NaN 值为 0\n",
    "data_df.fillna(0, inplace=True)\n",
    "# 检查非数值列\n",
    "non_numeric_cols = data_df.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_cols)\n",
    "\n",
    "# 将非数值列转换为数值类型（使用标签编码）\n",
    "label_encoders = {}\n",
    "for col in non_numeric_cols:\n",
    "    le = LabelEncoder()\n",
    "    data_df[col] = le.fit_transform(data_df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "\n",
    "# 确保所有特征列都是数值类型\n",
    "print(\"Data types after encoding:\\n\", data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'pickup_longitude',\n",
       "       'pickup_latitude', 'RateCodeID', 'store_and_fwd_flag',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount',\n",
       "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'total_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000000 entries, 919213 to 2187994\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   VendorID               1000000 non-null  int64  \n",
      " 1   tpep_pickup_datetime   1000000 non-null  int64  \n",
      " 2   tpep_dropoff_datetime  1000000 non-null  int64  \n",
      " 3   passenger_count        1000000 non-null  int64  \n",
      " 4   trip_distance          1000000 non-null  float64\n",
      " 5   pickup_longitude       1000000 non-null  float64\n",
      " 6   pickup_latitude        1000000 non-null  float64\n",
      " 7   RateCodeID             1000000 non-null  int64  \n",
      " 8   store_and_fwd_flag     1000000 non-null  int64  \n",
      " 9   dropoff_longitude      1000000 non-null  float64\n",
      " 10  dropoff_latitude       1000000 non-null  float64\n",
      " 11  payment_type           1000000 non-null  int64  \n",
      " 12  fare_amount            1000000 non-null  float64\n",
      " 13  extra                  1000000 non-null  float64\n",
      " 14  mta_tax                1000000 non-null  float64\n",
      " 15  tip_amount             1000000 non-null  float64\n",
      " 16  tolls_amount           1000000 non-null  float64\n",
      " 17  total_amount           1000000 non-null  float64\n",
      "dtypes: float64(11), int64(7)\n",
      "memory usage: 145.0 MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化数值特征\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data_df)\n",
    "# 将 NumPy 数组转换回 DataFrame\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data_df.columns)\n",
    "\n",
    "\n",
    "# 将标准化后的数据转换为torch张量\n",
    "x = torch.tensor(data_scaled, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 25], num_nodes=18, x=[1000000, 18])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 示例表格数据特征\n",
    "columns = data_df.columns\n",
    "\n",
    "# # 定义特征之间的关系\n",
    "relations = [\n",
    "    ('VendorID', 'tpep_pickup_datetime'),\n",
    "    ('VendorID', 'tpep_dropoff_datetime'),\n",
    "    ('tpep_pickup_datetime', 'tpep_dropoff_datetime'),\n",
    "    ('tpep_pickup_datetime', 'pickup_longitude'),\n",
    "    ('tpep_pickup_datetime', 'pickup_latitude'),\n",
    "    ('tpep_dropoff_datetime', 'dropoff_longitude'),\n",
    "    ('tpep_dropoff_datetime', 'dropoff_latitude'),\n",
    "    ('pickup_longitude', 'pickup_latitude'),\n",
    "    ('dropoff_longitude', 'dropoff_latitude'),\n",
    "    ('passenger_count', 'trip_distance'),\n",
    "    ('trip_distance', 'fare_amount'),\n",
    "    ('fare_amount', 'extra'),\n",
    "    ('fare_amount', 'mta_tax'),\n",
    "    ('fare_amount', 'tip_amount'),\n",
    "    ('fare_amount', 'tolls_amount'),\n",
    "    ('fare_amount', 'total_amount'),\n",
    "    ('extra', 'total_amount'),\n",
    "    ('mta_tax', 'total_amount'),\n",
    "    ('tip_amount', 'total_amount'),\n",
    "    ('tolls_amount', 'total_amount'),\n",
    "    ('RateCodeID', 'store_and_fwd_flag'),\n",
    "    ('RateCodeID', 'payment_type'),\n",
    "    ('payment_type', 'total_amount'),\n",
    "    ('store_and_fwd_flag', 'tpep_pickup_datetime'),\n",
    "    ('store_and_fwd_flag', 'tpep_dropoff_datetime')\n",
    "]\n",
    "# 定义特征之间的关系\n",
    "# relations = [\n",
    "#     ('tpep_pickup_datetime', 'tpep_dropoff_datetime'),\n",
    "#     ('tpep_pickup_datetime', 'pickup_longitude'),\n",
    "#     ('tpep_pickup_datetime', 'pickup_latitude'),\n",
    "#     ('tpep_dropoff_datetime', 'dropoff_longitude'),\n",
    "#     ('pickup_longitude', 'pickup_latitude'),\n",
    "#     ('passenger_count', 'trip_distance'),\n",
    "#     ('trip_distance', 'RateCodeID'),\n",
    "#     ('VendorID', 'store_and_fwd_flag'),\n",
    "#     ('VendorID', 'RateCodeID'),\n",
    "#     ('RateCodeID', 'store_and_fwd_flag')\n",
    "#     # 可以添加更多关系\n",
    "# ]\n",
    "# relations = [\n",
    "#     (\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"),\n",
    "#     (\"tpep_pickup_datetime\", \"passenger_count\"),\n",
    "#     (\"tpep_pickup_datetime\", \"trip_distance\"),\n",
    "#     (\"tpep_dropoff_datetime\", \"passenger_count\"),\n",
    "#     (\"tpep_dropoff_datetime\", \"trip_distance\"),\n",
    "#     # (\"passenger_count\", \"trip_distance\"),\n",
    "#     # (\"VendorID\", \"tpep_pickup_datetime\"),\n",
    "#     # (\"VendorID\", \"tpep_dropoff_datetime\"),\n",
    "#     # (\"VendorID\", \"passenger_count\"),\n",
    "#     # (\"VendorID\", \"trip_distance\")\n",
    "# ]\n",
    "# 创建空的无向图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加节点（每个特征作为一个节点）\n",
    "for col in columns:\n",
    "    G.add_node(col)\n",
    "\n",
    "# 添加边（根据特征之间的关系）\n",
    "for relation in relations:\n",
    "    G.add_edge(relation[0], relation[1])\n",
    "\n",
    "# 将NetworkX图转换为PyTorch Geometric图\n",
    "data = from_networkx(G)\n",
    "\n",
    "# 添加节点特征\n",
    "data.x = x\n",
    "\n",
    "# 映射特征列到索引\n",
    "feature_to_index = {col: i for i, col in enumerate(columns)}\n",
    "\n",
    "# 映射关系到索引\n",
    "edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "# 添加边\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "data.edge_index = edge_index\n",
    "\n",
    "\n",
    "# 确定设备（GPU 优先）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 将数据移动到设备\n",
    "data = data.to(device)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(18, 128)\n",
      "  (conv2): GCNConv(128, 128)\n",
      "  (fc): Linear(in_features=128, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, output_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = nn.Linear(hidden_channels, output_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "num_features = data.num_features\n",
    "hidden_channels = 128\n",
    "output_channels = num_features  # 确保输出维度与输入维度一致\n",
    "model = GCN(num_features, hidden_channels, output_channels).to(device)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0171\n",
      "Epoch 20, Loss: 0.0051\n",
      "Epoch 30, Loss: 0.0029\n",
      "Epoch 40, Loss: 0.0013\n",
      "Epoch 50, Loss: 0.0006\n",
      "Epoch 60, Loss: 0.0003\n",
      "Epoch 70, Loss: 0.0002\n",
      "Epoch 80, Loss: 0.0002\n",
      "Epoch 90, Loss: 0.0001\n",
      "Epoch 100, Loss: 0.0001\n",
      "Epoch 110, Loss: 0.0001\n",
      "Epoch 120, Loss: 0.0001\n",
      "Epoch 130, Loss: 0.0001\n",
      "Epoch 140, Loss: 0.0001\n",
      "Epoch 150, Loss: 0.0001\n",
      "Epoch 160, Loss: 0.0000\n",
      "Epoch 170, Loss: 0.0000\n",
      "Epoch 180, Loss: 0.0000\n",
      "Epoch 190, Loss: 0.0000\n",
      "Epoch 200, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# 创建数据加载器\n",
    "loader = DataLoader([data], batch_size=1280, shuffle=True)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 训练模型\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 1000, Time taken: 0.86 seconds\n",
      "Data size: 5000, Time taken: 4.27 seconds\n",
      "Data size: 10000, Time taken: 8.56 seconds\n",
      "Data size: 20000, Time taken: 17.37 seconds\n",
      "Data size: 50000, Time taken: 43.36 seconds\n",
      "Data size: 100000, Time taken: 86.69 seconds\n",
      "Data size: 200000, Time taken: 173.18 seconds\n",
      "Data size: 500000, Time taken: 432.81 seconds\n",
      "Data size: 1000000, Time taken: 870.02 seconds\n",
      "Time records: {1000: 0.8578667640686035, 5000: 4.27446985244751, 10000: 8.555078744888306, 20000: 17.36573314666748, 50000: 43.35615849494934, 100000: 86.6929943561554, 200000: 173.18003010749817, 500000: 432.8054893016815, 1000000: 870.01686668396}\n",
      "Time records have been saved to time_records.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import from_networkx\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def aggregate_instance_embeddings(data_scaled, G, model, batch_size=4096):\n",
    "    model.eval()\n",
    "    instance_embeddings_list = []\n",
    "\n",
    "    for i in range(0, len(data_scaled), batch_size):\n",
    "        batch_subgraphs = []\n",
    "        batch_node_features = []\n",
    "        for j in range(i, min(i + batch_size, len(data_scaled))):\n",
    "            # 创建子图\n",
    "            subgraph = G.copy()\n",
    "\n",
    "            # 创建节点特征张量\n",
    "            subgraph_data = data_scaled[j]\n",
    "\n",
    "            # 确保 x 的形状是 [num_nodes, num_features]，即 [1, 23]\n",
    "            node_features = torch.tensor(subgraph_data, dtype=torch.float).view(1, -1).repeat(len(columns), 1).to(device)\n",
    "\n",
    "            # 将 NetworkX 子图转换为 PyTorch Geometric 图\n",
    "            subgraph_data = from_networkx(subgraph)\n",
    "\n",
    "            # 更新子图的节点特征\n",
    "            subgraph_data.x = node_features\n",
    "\n",
    "            # 映射特征列到索引\n",
    "            feature_to_index = {col: idx for idx, col in enumerate(columns)}\n",
    "\n",
    "            # 映射关系到索引\n",
    "            edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "            # 添加边\n",
    "            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "            subgraph_data.edge_index = edge_index.to(device)\n",
    "\n",
    "            batch_subgraphs.append(subgraph_data)\n",
    "            batch_node_features.append(node_features)\n",
    "\n",
    "        # 创建批处理图\n",
    "        batch_graph = Batch.from_data_list(batch_subgraphs)\n",
    "\n",
    "        # 获取批处理中所有节点的特征嵌入\n",
    "        with torch.no_grad():\n",
    "            node_embeddings = model(batch_graph.to(device))\n",
    "\n",
    "        # 逐个图聚合节点嵌入到实例嵌入\n",
    "        batch_size_actual = len(batch_subgraphs)\n",
    "        start_idx = 0\n",
    "        for j in range(batch_size_actual):\n",
    "            num_nodes = len(columns)\n",
    "            instance_embedding = node_embeddings[start_idx:start_idx + num_nodes].mean(dim=0, keepdim=True)\n",
    "            instance_embeddings_list.append(instance_embedding)\n",
    "            start_idx += num_nodes\n",
    "\n",
    "    instance_embeddings = torch.cat(instance_embeddings_list, dim=0)\n",
    "    return instance_embeddings\n",
    "\n",
    "# 设置不同的数据大小\n",
    "data_sizes = [1000, 5000, 10000, 20000, 50000, 100000, 200000, 500000, 1000000]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 用于记录每个数据大小的运行时间\n",
    "time_records = {}\n",
    "\n",
    "for size in data_sizes:\n",
    "    data_scaled = np.random.rand(size, len(columns))  # 随机生成数据\n",
    "\n",
    "    start_time = time.time()\n",
    "    instance_embeddings = aggregate_instance_embeddings(data_scaled, G, model)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_records[size] = elapsed_time\n",
    "    print(f\"Data size: {size}, Time taken: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# 将时间记录保存到JSON文件中\n",
    "with open('time_records.json', 'w') as f:\n",
    "    json.dump(time_records, f, indent=4)\n",
    "\n",
    "print(\"Time records:\", time_records)\n",
    "print(\"Time records have been saved to time_records.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance_embeddings\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# 获取每个实例的特征嵌入\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m instance_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_instance_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(instance_embeddings)\n",
      "Cell \u001b[0;32mIn[45], line 42\u001b[0m, in \u001b[0;36maggregate_instance_embeddings\u001b[0;34m(data_scaled, G, model, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m     batch_node_features\u001b[38;5;241m.\u001b[39mappend(node_features)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 创建批处理图\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m batch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_subgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 获取批处理中所有节点的特征嵌入\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.11/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mainenv/lib/python3.11/site-packages/torch_geometric/data/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    142\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m [store\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m    143\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 144\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, slice_dict, inc_dict\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "def aggregate_instance_embeddings(data_scaled, G, model, batch_size=4096):\n",
    "    model.eval()\n",
    "    instance_embeddings_list = []\n",
    "\n",
    "    for i in range(0, len(data_scaled), batch_size):\n",
    "        batch_subgraphs = []\n",
    "        batch_node_features = []\n",
    "        for j in range(i, min(i + batch_size, len(data_scaled))):\n",
    "            # 创建子图\n",
    "            subgraph = G.copy()\n",
    "\n",
    "            # 创建节点特征张量\n",
    "            subgraph_data = data_scaled[j]\n",
    "\n",
    "            # 确保 x 的形状是 [num_nodes, num_features]，即 [1, 23]\n",
    "            node_features = torch.tensor(subgraph_data, dtype=torch.float).view(1, -1).repeat(len(columns), 1).to(device)\n",
    "\n",
    "            # 将 NetworkX 子图转换为 PyTorch Geometric 图\n",
    "            subgraph_data = from_networkx(subgraph)\n",
    "\n",
    "            # 更新子图的节点特征\n",
    "            subgraph_data.x = node_features\n",
    "\n",
    "            # 映射特征列到索引\n",
    "            feature_to_index = {col: idx for idx, col in enumerate(columns)}\n",
    "\n",
    "            # 映射关系到索引\n",
    "            edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "            # 添加边\n",
    "            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "            subgraph_data.edge_index = edge_index.to(device)\n",
    "\n",
    "            batch_subgraphs.append(subgraph_data)\n",
    "            batch_node_features.append(node_features)\n",
    "\n",
    "        # 创建批处理图\n",
    "        batch_graph = Batch.from_data_list(batch_subgraphs)\n",
    "\n",
    "        # 获取批处理中所有节点的特征嵌入\n",
    "        with torch.no_grad():\n",
    "            node_embeddings = model(batch_graph.to(device))\n",
    "\n",
    "        # 逐个图聚合节点嵌入到实例嵌入\n",
    "        batch_size_actual = len(batch_subgraphs)\n",
    "        start_idx = 0\n",
    "        for j in range(batch_size_actual):\n",
    "            num_nodes = len(columns)\n",
    "            instance_embedding = node_embeddings[start_idx:start_idx + num_nodes].mean(dim=0, keepdim=True)\n",
    "            instance_embeddings_list.append(instance_embedding)\n",
    "            start_idx += num_nodes\n",
    "\n",
    "    instance_embeddings = torch.cat(instance_embeddings_list, dim=0)\n",
    "    return instance_embeddings\n",
    "\n",
    "# 获取每个实例的特征嵌入\n",
    "instance_embeddings = aggregate_instance_embeddings(data_scaled, G, model)\n",
    "print(instance_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0560e-01, -3.1195e-02,  3.4954e-01,  ...,  2.7257e-02,\n",
      "          9.4607e-01,  1.1783e+00],\n",
      "        [ 9.0782e-01,  1.2033e+00,  1.1596e-01,  ..., -3.6276e-02,\n",
      "          9.2317e-01,  5.7591e-01],\n",
      "        [ 1.0101e+00, -1.2002e-01,  5.1213e-02,  ..., -1.7638e-02,\n",
      "          1.3709e+00,  1.0080e+00],\n",
      "        ...,\n",
      "        [ 2.8917e-01,  4.7244e-02,  9.6095e-02,  ..., -5.0912e-02,\n",
      "          8.7401e-01,  3.8242e-01],\n",
      "        [ 7.8607e-01,  1.2082e+00,  2.1546e-01,  ..., -8.9726e-04,\n",
      "          9.0406e-01,  4.1652e-02],\n",
      "        [ 8.3822e-01,  2.7921e-02,  4.0561e-03,  ..., -1.3699e-02,\n",
      "          1.3272e+00,  2.8801e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.utils import from_networkx\n",
    "\n",
    "# def aggregate_instance_embeddings(data_scaled, G, model):\n",
    "#     model.eval()\n",
    "#     instance_embeddings_list = []\n",
    "\n",
    "#     for i in range(len(data_scaled)):\n",
    "#         # 创建子图\n",
    "#         subgraph = G.copy()\n",
    "\n",
    "#         # 创建节点特征张量\n",
    "#         subgraph_data = data_scaled[i]\n",
    "\n",
    "#         # 确保 x 的形状是 [num_nodes, num_features]，即 [1, 23]\n",
    "#         node_features = torch.tensor(subgraph_data, dtype=torch.float).view(1, -1).repeat(len(columns), 1).to(device)\n",
    "\n",
    "#         # 将 NetworkX 子图转换为 PyTorch Geometric 图\n",
    "#         subgraph_data = from_networkx(subgraph)\n",
    "\n",
    "#         # 更新子图的节点特征\n",
    "#         subgraph_data.x = node_features\n",
    "\n",
    "#         # 映射特征列到索引\n",
    "#         feature_to_index = {col: idx for idx, col in enumerate(columns)}\n",
    "\n",
    "#         # 映射关系到索引\n",
    "#         edges = [(feature_to_index[src], feature_to_index[dst]) for src, dst in relations]\n",
    "\n",
    "#         # 添加边\n",
    "#         edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "#         subgraph_data.edge_index = edge_index.to(device)\n",
    "\n",
    "#         # 获取特征嵌入\n",
    "#         with torch.no_grad():\n",
    "#             node_embeddings = model(subgraph_data)\n",
    "\n",
    "#         # 聚合节点嵌入到实例嵌入\n",
    "#         instance_embedding = node_embeddings.mean(dim=0, keepdim=True)\n",
    "#         instance_embeddings_list.append(instance_embedding)\n",
    "\n",
    "#     instance_embeddings = torch.cat(instance_embeddings_list, dim=0)\n",
    "#     return instance_embeddings\n",
    "\n",
    "# # 获取每个实例的特征嵌入\n",
    "# instance_embeddings = aggregate_instance_embeddings(data_scaled, G, model)\n",
    "# print(instance_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011392</td>\n",
       "      <td>0.576693</td>\n",
       "      <td>0.561337</td>\n",
       "      <td>0.194952</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>1.186569</td>\n",
       "      <td>-0.053824</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>1.183097</td>\n",
       "      <td>-0.033423</td>\n",
       "      <td>-0.011998</td>\n",
       "      <td>0.398114</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>1.138101</td>\n",
       "      <td>0.035433</td>\n",
       "      <td>0.008031</td>\n",
       "      <td>0.381434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.016649</td>\n",
       "      <td>1.082896</td>\n",
       "      <td>1.073180</td>\n",
       "      <td>0.195673</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>0.037018</td>\n",
       "      <td>0.795961</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.091569</td>\n",
       "      <td>1.147589</td>\n",
       "      <td>-0.015760</td>\n",
       "      <td>0.368101</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>1.142203</td>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.361656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.018290</td>\n",
       "      <td>0.673057</td>\n",
       "      <td>0.666099</td>\n",
       "      <td>0.194751</td>\n",
       "      <td>0.010105</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.800490</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.087240</td>\n",
       "      <td>1.147548</td>\n",
       "      <td>-0.015181</td>\n",
       "      <td>0.384489</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>1.138080</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.378201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.159951</td>\n",
       "      <td>0.576652</td>\n",
       "      <td>0.569610</td>\n",
       "      <td>0.194156</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.794604</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.092195</td>\n",
       "      <td>1.144462</td>\n",
       "      <td>-0.006746</td>\n",
       "      <td>0.368006</td>\n",
       "      <td>0.011595</td>\n",
       "      <td>1.140070</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.356928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017218</td>\n",
       "      <td>0.093690</td>\n",
       "      <td>0.083110</td>\n",
       "      <td>0.615355</td>\n",
       "      <td>-0.004182</td>\n",
       "      <td>0.023136</td>\n",
       "      <td>0.806771</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>1.145515</td>\n",
       "      <td>0.384091</td>\n",
       "      <td>0.377013</td>\n",
       "      <td>0.010267</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>-0.005276</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.011392  0.576693  0.561337  0.194952  0.003531  1.186569 -0.053824   \n",
       "1 -0.016649  1.082896  1.073180  0.195673 -0.000514  0.037018  0.795961   \n",
       "2 -0.018290  0.673057  0.666099  0.194751  0.010105  0.036345  0.800490   \n",
       "3  1.159951  0.576652  0.569610  0.194156 -0.000214  0.040761  0.794604   \n",
       "4 -0.017218  0.093690  0.083110  0.615355 -0.004182  0.023136  0.806771   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.019801  0.010904  1.183097 -0.033423 -0.011998  0.398114  0.012938   \n",
       "1  0.012805  0.004696  0.091569  1.147589 -0.015760  0.368101  0.005186   \n",
       "2  0.013701  0.009253  0.087240  1.147548 -0.015181  0.384489  0.007494   \n",
       "3  0.012217  0.007623  0.092195  1.144462 -0.006746  0.368006  0.011595   \n",
       "4  0.015518  0.010586  0.083672  1.145515  0.384091  0.377013  0.010267   \n",
       "\n",
       "         14        15        16        17  \n",
       "0  1.138101  0.035433  0.008031  0.381434  \n",
       "1  1.142203  0.017424  0.004471  0.361656  \n",
       "2  1.138080  0.026607  0.008376  0.378201  \n",
       "3  1.140070  0.015737  0.001840  0.356928  \n",
       "4  1.151090 -0.005276  0.005237  0.360295  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 PyTorch 张量转换为 Pandas DataFrame\n",
    "instance_embeddings_df = pd.DataFrame(instance_embeddings.cpu().numpy())\n",
    "\n",
    "instance_embeddings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079737</td>\n",
       "      <td>0.505302</td>\n",
       "      <td>0.463191</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>0.307375</td>\n",
       "      <td>0.932816</td>\n",
       "      <td>0.039189</td>\n",
       "      <td>0.048556</td>\n",
       "      <td>0.059319</td>\n",
       "      <td>0.954976</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.079452</td>\n",
       "      <td>0.268367</td>\n",
       "      <td>0.344981</td>\n",
       "      <td>0.819549</td>\n",
       "      <td>0.306108</td>\n",
       "      <td>0.097158</td>\n",
       "      <td>0.254161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076005</td>\n",
       "      <td>0.895363</td>\n",
       "      <td>0.861375</td>\n",
       "      <td>0.164925</td>\n",
       "      <td>0.287336</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.811230</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.054559</td>\n",
       "      <td>0.079511</td>\n",
       "      <td>0.927222</td>\n",
       "      <td>0.076495</td>\n",
       "      <td>0.226035</td>\n",
       "      <td>0.302740</td>\n",
       "      <td>0.824743</td>\n",
       "      <td>0.270138</td>\n",
       "      <td>0.087177</td>\n",
       "      <td>0.230025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074839</td>\n",
       "      <td>0.579556</td>\n",
       "      <td>0.544690</td>\n",
       "      <td>0.164162</td>\n",
       "      <td>0.339954</td>\n",
       "      <td>0.057394</td>\n",
       "      <td>0.815345</td>\n",
       "      <td>0.043538</td>\n",
       "      <td>0.058053</td>\n",
       "      <td>0.076038</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>0.076951</td>\n",
       "      <td>0.249149</td>\n",
       "      <td>0.315314</td>\n",
       "      <td>0.819523</td>\n",
       "      <td>0.288479</td>\n",
       "      <td>0.098127</td>\n",
       "      <td>0.250215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.911355</td>\n",
       "      <td>0.505270</td>\n",
       "      <td>0.469627</td>\n",
       "      <td>0.163669</td>\n",
       "      <td>0.288823</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>0.809997</td>\n",
       "      <td>0.042318</td>\n",
       "      <td>0.056804</td>\n",
       "      <td>0.080013</td>\n",
       "      <td>0.925273</td>\n",
       "      <td>0.083580</td>\n",
       "      <td>0.225901</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.822043</td>\n",
       "      <td>0.266767</td>\n",
       "      <td>0.079801</td>\n",
       "      <td>0.224255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.133118</td>\n",
       "      <td>0.091159</td>\n",
       "      <td>0.512327</td>\n",
       "      <td>0.269159</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.821051</td>\n",
       "      <td>0.045033</td>\n",
       "      <td>0.059075</td>\n",
       "      <td>0.073176</td>\n",
       "      <td>0.925929</td>\n",
       "      <td>0.390758</td>\n",
       "      <td>0.238606</td>\n",
       "      <td>0.330423</td>\n",
       "      <td>0.835997</td>\n",
       "      <td>0.224797</td>\n",
       "      <td>0.089325</td>\n",
       "      <td>0.228365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.079737  0.505302  0.463191  0.164329  0.307375  0.932816  0.039189   \n",
       "1  0.076005  0.895363  0.861375  0.164925  0.287336  0.057906  0.811230   \n",
       "2  0.074839  0.579556  0.544690  0.164162  0.339954  0.057394  0.815345   \n",
       "3  0.911355  0.505270  0.469627  0.163669  0.288823  0.060755  0.809997   \n",
       "4  0.075601  0.133118  0.091159  0.512327  0.269159  0.047341  0.821051   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.048556  0.059319  0.954976  0.191044  0.079452  0.268367  0.344981   \n",
       "1  0.042802  0.054559  0.079511  0.927222  0.076495  0.226035  0.302740   \n",
       "2  0.043538  0.058053  0.076038  0.927197  0.076951  0.249149  0.315314   \n",
       "3  0.042318  0.056804  0.080013  0.925273  0.083580  0.225901  0.337662   \n",
       "4  0.045033  0.059075  0.073176  0.925929  0.390758  0.238606  0.330423   \n",
       "\n",
       "         14        15        16        17  \n",
       "0  0.819549  0.306108  0.097158  0.254161  \n",
       "1  0.824743  0.270138  0.087177  0.230025  \n",
       "2  0.819523  0.288479  0.098127  0.250215  \n",
       "3  0.822043  0.266767  0.079801  0.224255  \n",
       "4  0.835997  0.224797  0.089325  0.228365  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化数值特征\n",
    "scaler = MinMaxScaler()\n",
    "instance_embeddings_df_scaled = scaler.fit_transform(instance_embeddings_df)\n",
    "# 将标准化后的数据转换回 DataFrame\n",
    "instance_embeddings_df_scaled = pd.DataFrame(instance_embeddings_df_scaled, columns=instance_embeddings_df.columns)\n",
    "\n",
    "instance_embeddings_df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance embeddings saved to /home/sdong/data/hotel_booking/hotel_booking_string_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存为 CSV 文件\n",
    "csv_file_path = '/home/sdong/data/hotel_booking/yellow_tripdata_sample_1000000_embeddings.csv'\n",
    "instance_embeddings_df_scaled.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'Instance embeddings saved to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
